Hive：
1、简介：
	Hive是一个基于Hadoop文件系统之上的数据仓库架构。
	Hive不能提供数据排序和查询cache功能，也不提供在线事物处理，不停实时的查询和记录级的更新，但Hive能更好的处理不变的大规模数据集上的批量任务。
	所以Hive最大的价值是可扩展性、可延展性，并且拥有良好的容错性和低约束的数据输入格式。
	Hive的存储是建立在Hadoop文件系统之上的。Hive本身没有专门的数据存储格式，也不能为数据建立索引，用户可以非常自由地组织Hive中的表，只需要在创建表的时候告诉Hive数据中的列分隔符和行分隔符就可以解析数据了。
	Hive中主要包含四种数据模型：
		表：
			和数据库中的表在概念上是类似的，每个表在Hive中都有一个对应的存储目录。
		外部表：
			外部表指向已经在HDFS中存在的数据，也可以创建分区。他和表在元数据的组织上是相同的，而实际数据的存储则存在较大差异，主要表现在以下两点上。
			1）创建表的操作包含两个步骤，表创建过程和数据加载步骤。删除表时，表中的数据和元数据都将被同时删除。
			2）外部表的创建只有一个步骤，加载数据和创建表同时完成。删除外部表时，仅会删除元数据，表中的数据不会被删除。
		分区：
			Hive中每个分区都对应数据库中相应分区列的一个索引，但是分区的组织方式和传统关系型数据库不同。在Hive中，表中的一个分区对于表下的一个目录，所有分区的数据都存储在对应的目录中。
		桶：
			桶对指定列进行哈希计算时，根据哈希值切分数据，每个桶对应一个文件。
	Hive中的元数据存储：
		由于Hive的元数据可能要面临不断的更新、修改和读取，所以它显然不适合使用Hadoop文件系统进行存储。目前Hive将元数据存储在RDBMS中，比如默认的Derby，MySQL。
2、Hive的基本操作：
	
	 a、配置Hive：
	 	
	 b、监控日志：
	 	
	 c、
3、 ：
	a、
	b、
	c、
	d、
4、 
	a、 ：

5、 
	a、 ：

	b、 ：
		
6、Hive的优化：
	Hive是针对不同的查询进行优化的，优化可以通过配置来进行控制。
	a、列裁剪（Column Pruning）
		读数据时，只读取查询中需要用到的列，而忽略其他列。
		要实现列裁剪，需要设置参数hive.optimize.cp=true。
	b、分区裁剪（Partition Pruning）
		在查询过程中减少不必要的分区。
		要实现分区裁剪，需要设置参数hive.optimize.cp=true。
	c、Join操作
		当使用写有join操作的查询语句时，有一条原则：应该将条目少的表/子查询放在join
		操作符的左边。原因是在join操作的reduce阶段，位于join操作符左边的标的内容会被加载到内存中，将条目少的表放在左边，这样可以有效减少发生内存溢出的几率。
	d、Map Join操作
		map Join操作无需reduce操作就可以在map阶段全部完成，前提是在map过程中可以访问
		到全部需要的数据。
	e、Group By操作
		进行Group By操作时需要注意以下两点：
		a)map端部分聚合，这时需要修改的参数为：hive.mao.aggr=true，用于设定是否在
		map端进行聚合，默认为true。
			hive.groupby.mapaggr.checkinterval=100000,用于设定在map端进行聚合操
			作的条目数。
		b)有数据倾斜（数据分布不均匀）时进行负载均衡。
		此处需要设定hive.groupby.skewindata,当选项设定为true是，生成的查询计划会有
		两个MapReduce任务。第一个MapReduce中，map的输出结果集合会随机分不到reduce中，每个reduce都做部分聚合操作，并输出结果。
		第二个MapReduce任务再根据预处理的数据结果按照Group By Key 分不到reduce中，
		最后完成最终的聚合操作。
	f、合并小文件
		文件数据过多，会给HDFS带来很大的压力，并且会影响处理的效率，因此我们可以通过合并
		map和reduce的结果文件来消除这样的额影响。
		需要进行的设定有以下三个：
		hive.merge.mapfiles = true,设定是否合并map输出文件，默认为true
		hive.merge.mapredfiles = false,设定是否合并reduce输出文件，默认为false
		hive.merge.size.per.task = **,设定合并文件的大小，默认值为256000000。

	